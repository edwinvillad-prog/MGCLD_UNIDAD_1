# app_bondad_ajuste_consolidada.py
# Aplicaci√≥n profesional en Streamlit ‚Äî Bondad de ajuste y validaci√≥n avanzada
# Fases 1, 2 y 3

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from scipy.stats import (
    chisquare, poisson, binom, hypergeom,
    norm, expon, gamma, weibull_min, lognorm,
    kstest, anderson
)
from math import comb

# Para la prueba de Lilliefors (solo Normalidad) disponible en statsmodels
from statsmodels.stats.diagnostic import kstest_normal


# =========================
# CONFIG GENERAL
# =========================
st.set_page_config(
    page_title="Bondad de Ajuste y Validaci√≥n ‚Äî Posgrado",
    page_icon="üìä",
    layout="wide"
)

st.title("üìä Laboratorio interactivo de bondad de ajuste y validaci√≥n")
st.markdown("### Maestr√≠a en Gesti√≥n de la Calidad de la Leche y sus Derivados")

# =========================
# SIDEBAR (solo una vez)
# =========================
st.sidebar.header("Opciones generales")
st.sidebar.markdown("üë§ **M.Sc. Edwin Villarreal, F√≠s.** ")

alpha = st.sidebar.selectbox("Nivel de significancia (Œ±)", [0.01, 0.05, 0.10], index=1)

# =========================
# CARGA DE ARCHIVO (robusta)
# =========================
st.sidebar.markdown("### üìÇ Cargar archivo")
uploaded_file = st.sidebar.file_uploader("Subir archivo CSV/Excel", type=["csv", "xlsx"])
data = None

if uploaded_file:
    try:
        # --- Lectura autom√°tica seg√∫n extensi√≥n ---
        if uploaded_file.name.endswith(".csv"):
            data = pd.read_csv(uploaded_file)
        else:
            data = pd.read_excel(uploaded_file)

        # --- üîß Limpieza de encabezados ---
        data.columns = data.columns.map(lambda c: str(c).strip())

        # --- Mostrar confirmaci√≥n y vista previa ---
        st.sidebar.success(f"‚úÖ Archivo cargado correctamente: {uploaded_file.name}")
        st.sidebar.write("**Columnas detectadas:**")
        st.sidebar.dataframe(data.head(3))

        # --- Verificaci√≥n r√°pida de tipo de dato ---
        numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
        if not numeric_cols:
            st.sidebar.warning("‚ö†Ô∏è No se detectaron columnas num√©ricas. "
                               "Revise el formato o los encabezados de su archivo.")

    except Exception as e:
        st.sidebar.error(f"‚ùå Error al leer el archivo: {e}")
else:
    st.sidebar.info("‚ö†Ô∏è Cargue un archivo CSV o Excel con encabezados en la primera fila.")


decision_mode_disc = st.sidebar.radio(
    "Modo de decisi√≥n (discretas)", 
    ["Docente", "Estricto/Industrial"],
    key="decision_mode_disc"
)

decision_mode_cont = st.sidebar.radio(
    "Modo de decisi√≥n (continuas)",
    ["Docente", "Estricto/Industrial"],
    index=0,
    key="decision_mode_cont"
)


# =========================
# TABS PRINCIPALES
# =========================
tabs = st.tabs([
    "üìò Teor√≠a",
    "üé≤ Distribuciones discretas",
    "üìà Distribuciones continuas",
    "üßÆ Validaci√≥n avanzada discreta",
    "üìä Validaci√≥n avanzada continua",
    "‚ö†Ô∏è Escenarios cr√≠ticos"
])

# =========================
# TAB 1 ‚Äî TEOR√çA
# =========================
with tabs[0]:
    st.header("üìò Teor√≠a y condiciones de aplicaci√≥n")

    # Distribuciones discretas
    st.subheader("üé≤ Distribuciones discretas")
    st.markdown("""
    - **Chi¬≤** ‚Üí comparaci√≥n de frecuencias observadas y esperadas.  
      - **Tipo:** prueba **no param√©trica**.  
      - **Condiciones:** $n ‚â• 30$, frecuencias esperadas ‚â• 5.  
      - **Aplicaci√≥n en l√°cteos:** conteo de **UFC (Unidades Formadoras de Colonias)**, defectos en envases.  

      **F√≥rmula del estad√≠stico:**  
      $$
      \\chi^2 = \\sum_{i=1}^k \\frac{(O_i - E_i)^2}{E_i}
      $$
      donde $O_i$ son las frecuencias observadas y $E_i$ las esperadas.  

    - **Poisson**: conteo de microorganismos.  
    - **Binomial**: rechazo de lotes con muestras defectuosas.  
    - **Hipergeom√©trica**: muestreo sin reemplazo.  

    ‚ö†Ô∏è *Si $n < 20$ o hay frecuencias esperadas < 5 ‚Üí aplicar prueba exacta o simulaci√≥n Monte Carlo.*
    """)

    # Distribuciones continuas
    st.subheader("üìà Distribuciones continuas")
    st.markdown("""
    - **Normal**: prote√≠na, grasa, densidad, pH.  
    - **Exponencial**: tiempos de falla, vida √∫til.  
    - **Weibull**: confiabilidad, vida √∫til de quesos/yogures.  
    - **Gamma**: tiempos de fermentaci√≥n.  
    - **Lognormal**: procesos de degradaci√≥n.  

    - **Kolmogorov‚ÄìSmirnov (KS)**  
      - **Tipo:** prueba **no param√©trica**.  
      - **Condiciones:** muestra continua, $n ‚â• 20$.  
      - **F√≥rmula:**  
        $$
        D = \\sup_x \\left| F_n(x) - F(x) \\right|
        $$  
        donde $F_n(x)$ es la CDF emp√≠rica y $F(x)$ la te√≥rica.  

    - **Lilliefors** (variante de KS)  
      - **Tipo:** no param√©trica.  
      - Se aplica cuando los par√°metros de la distribuci√≥n se **estiman de la muestra** (ej. Normal, Exponencial).  

    - **Shapiro‚ÄìWilk**  
      - **Tipo:** param√©trica.  
      - Dise√±ada para Normalidad con **muestras peque√±as (n < 20)**.  

    - **Anderson‚ÄìDarling (AD)**  
      - **Tipo:** no param√©trica.  
      - Requiere $n ‚â• 8$.  
      - Mayor sensibilidad en las colas de la distribuci√≥n.  
      - Muy usada en **vida √∫til y confiabilidad**.  
    """)

    # Validaci√≥n y regla pr√°ctica
    st.subheader("üß™ Validaci√≥n pr√°ctica")
    st.markdown("""
    - **Chi¬≤** ‚Üí discretas.  
    - **Exacta/Fisher** ‚Üí discretas con $n < 20$ o esperados < 5.  
    - **KS cl√°sico** ‚Üí continuas (n ‚â• 20, par√°metros conocidos).  
    - **Lilliefors** ‚Üí Normal/Exponencial con par√°metros estimados.  
    - **Shapiro‚ÄìWilk** ‚Üí Normalidad en muestras peque√±as (n < 20).  
    - **Anderson‚ÄìDarling** ‚Üí n ‚â• 8, sensible en colas.  

    üîç Adem√°s de las pruebas num√©ricas, se recomienda inspecci√≥n visual mediante **gr√°ficos P‚ÄìP y Q‚ÄìQ**.

    ‚úÖ **Regla pr√°ctica:**  
    - Si $p > Œ±$ ‚Üí **No se rechaza H‚ÇÄ** (ajuste adecuado).  
    - Si $p ‚â§ Œ±$ ‚Üí **Se rechaza H‚ÇÄ** (el modelo no explica bien los datos).  
    """)

# =========================
# TAB 2 ‚Äî DISTRIBUCIONES DISCRETAS
# =========================
with tabs[1]:
    st.header("üé≤ Ajuste de distribuciones discretas")
        # Banner con contexto actual
    st.info(f"üîé Nivel de significancia actual: **Œ± = {alpha}**\n\n"
            f"üìå Modo de decisi√≥n: **{decision_mode_disc}**")

    if data is not None:
       
        # --- üîß Mostrar solo columnas num√©ricas ---
        numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
        if not numeric_cols:
            st.error("‚ùå No hay columnas num√©ricas en el archivo. "
                    "Revise que el archivo tenga datos num√©ricos (sin texto).")
            st.stop()

        variable = st.selectbox("Seleccione variable discreta", numeric_cols, key="var_disc")


        dist_choice = st.radio("Distribuci√≥n de referencia", ["Poisson", "Binomial", "Hipergeom√©trica"], key="dist_disc")

        x = data[variable].dropna().values
        # --- üîß Validaci√≥n de discreci√≥n ---
        if np.any(x % 1 != 0):
            st.warning("‚ö†Ô∏è La variable seleccionada tiene valores decimales. "
                    "Se redondear√°n al entero m√°s cercano para aplicar la prueba discreta.")
            x = np.round(x).astype(int)
        else:
            x = x.astype(int)

        x = np.clip(x, 0, None)  # Evita valores negativos

        obs_counts = np.bincount(x)
        n = len(x)

        # ‚ö†Ô∏è Advertencia autom√°tica si n < 20
        small_sample = False
        if n < 20:
            small_sample = True
            st.warning("‚ö†Ô∏è Tama√±o de muestra muy peque√±o (n < 20). "
                       "El test Chi¬≤ puede tener poca validez. "
                       "Interprete los resultados con precauci√≥n.")

        if dist_choice == "Poisson":
            lam = np.mean(x)
            exp_counts = [poisson.pmf(k, lam) * n for k in range(len(obs_counts))]
            dist_info = f"Poisson(Œª={lam:.2f})"

        elif dist_choice == "Binomial":
            n_trials = st.number_input("N√∫mero de ensayos (n)", 1, 100, 10)
            p = np.mean(x) / n_trials
            exp_counts = [binom.pmf(k, n_trials, p) * n for k in range(len(obs_counts))]
            dist_info = f"Binomial(n={n_trials}, p={p:.2f})"

        else:  # Hipergeom√©trica
            N = st.number_input("Tama√±o poblaci√≥n (N)", 1, 1000, 50)
            K = st.number_input("√âxitos en poblaci√≥n (K)", 1, int(N), 10)
            n_sample = st.number_input("Tama√±o de muestra (n)", 1, int(N), 10)
            exp_counts = [hypergeom.pmf(k, N, K, n_sample) * n for k in range(len(obs_counts))]
            dist_info = f"Hipergeom√©trica(N={N}, K={K}, n={n_sample})"

        exp_counts = np.array(exp_counts)
        exp_counts *= n / exp_counts.sum()

        # ‚ö†Ô∏è Advertencia si hay frecuencias esperadas < 5
        low_expected = np.sum(exp_counts < 5)
        if low_expected > 0:
            st.warning(f"‚ö†Ô∏è Se detectaron {low_expected} categor√≠as con frecuencias esperadas < 5. "
                       "Esto puede afectar la validez del test Chi¬≤.")

        # =========================
        # 1) Chi¬≤ cl√°sico
        # =========================
        chi2, pval = chisquare(obs_counts, f_exp=exp_counts)
        st.subheader("üìà Chi¬≤ cl√°sico")
        st.write(f"Estad√≠stico = {chi2:.3f}, p-valor = {pval:.4f}")

        # =========================
        # 2) Monte Carlo (simulaci√≥n p-valor)
        # =========================
        def chi2_montecarlo(obs, exp, n_sim=5000):
            chi2_obs, _ = chisquare(obs, f_exp=exp)
            probs = exp / np.sum(exp)
            n_tot = np.sum(obs)
            sims = []
            for _ in range(n_sim):
                sim_data = np.random.multinomial(n_tot, probs)
                chi2_sim, _ = chisquare(sim_data, f_exp=exp)
                sims.append(chi2_sim)
            pval_mc = np.mean([s >= chi2_obs for s in sims])
            return chi2_obs, pval_mc

        chi2_mc, pval_mc = None, None
        if low_expected > 0 or small_sample:
            chi2_mc, pval_mc = chi2_montecarlo(obs_counts, exp_counts, n_sim=5000)
            st.subheader("üé≤ Chi¬≤ con Monte Carlo")
            st.write(f"Estad√≠stico = {chi2_mc:.3f}, p-valor simulado = {pval_mc:.4f}")

        # =========================
        # 3) Opciones adicionales
        # =========================
        if small_sample or low_expected > 0:
            st.markdown("### üîß Opciones adicionales de validaci√≥n")

            # --- Reagrupar categor√≠as autom√°ticamente ---
            if st.button("üìä Reagrupar categor√≠as autom√°ticamente"):
                obs = obs_counts.copy()
                exp = exp_counts.copy()

                while np.any(exp < 5) and len(exp) > 1:
                    if exp[0] < 5:  
                        exp[1] += exp[0]; obs[1] += obs[0]
                        exp, obs = exp[1:], obs[1:]
                    elif exp[-1] < 5:  
                        exp[-2] += exp[-1]; obs[-2] += obs[-1]
                        exp, obs = exp[:-1], obs[:-1]
                    else:
                        idx = np.argmin(exp)
                        if idx > 0:
                            exp[idx-1] += exp[idx]; obs[idx-1] += obs[idx]
                            exp, obs = np.delete(exp, idx), np.delete(obs, idx)
                        else:
                            exp[1] += exp[0]; obs[1] += obs[0]
                            exp, obs = exp[1:], obs[1:]

                chi2_adj, pval_adj = chisquare(obs, f_exp=exp)
                st.write("### üìä Chi¬≤ tras reagrupar categor√≠as")
                st.write(f"Estad√≠stico = {chi2_adj:.3f}, p-valor = {pval_adj:.4f}")
                if pval_adj < alpha:
                    st.error("‚ùå Rechazar H‚ÇÄ tras reagrupar.")
                else:
                    st.success("‚úÖ No rechazar H‚ÇÄ tras reagrupar.")

            # --- Prueba exacta ---
            if st.button("üéØ Aplicar prueba exacta"):
                from scipy.stats import binomtest, fisher_exact
                if dist_choice == "Binomial":
                    k = np.sum(x)  
                    n_total = len(x)
                    p0 = np.mean(x) / n_trials if n_trials > 0 else 0.5
                    test_res = binomtest(k, n_total, p=p0)
                    st.write(f"**Prueba Binomial exacta:** √©xitos={k}, n={n_total}, p-valor = {test_res.pvalue:.4f}")
                    if test_res.pvalue < alpha:
                        st.error("‚ùå Rechazar H‚ÇÄ (Binomial exacta).")
                    else:
                        st.success("‚úÖ No rechazar H‚ÇÄ (Binomial exacta).")
                elif len(obs_counts) == 2:  
                    tabla = np.array([[obs_counts[0], obs_counts[1]],
                                      [n - obs_counts[0], n - obs_counts[1]]])
                    odds, p_fisher = fisher_exact(tabla)
                    st.write(f"**Prueba de Fisher (2x2):** p-valor = {p_fisher:.4f}")
                    if p_fisher < alpha:
                        st.error("‚ùå Rechazar H‚ÇÄ (Fisher).")
                    else:
                        st.success("‚úÖ No rechazar H‚ÇÄ (Fisher).")
                else:
                    st.info("‚ÑπÔ∏è La prueba exacta est√° implementada solo para Binomial y tablas 2√ó2.")

            # --- Aumentar tama√±o de muestra ---
            if st.button("‚ûï Aumentar tama√±o de muestra"):
                st.info("üìå Recolecte m√°s observaciones (ideal n ‚â• 30). "
                        "Con m√°s datos, las frecuencias esperadas aumentan y el test Chi¬≤ gana potencia estad√≠stica.")

        # =========================
        # üìå Dictamen final
        # =========================
        st.markdown("---")
        st.subheader("üßæ Dictamen final")

        chi2_reject = (pval < alpha)
        mc_reject = (pval_mc < alpha) if pval_mc is not None else None

        if decision_mode_disc == "Estricto/Industrial":
            # Si alguna prueba primaria rechaza ‚Üí rechazo
            if (chi2_reject or (mc_reject is True)):
                driver = "Monte Carlo" if mc_reject else "Chi¬≤ cl√°sico"
                st.error(f"**Dictamen final (estricto):** Rechazar H‚ÇÄ (Œ±={alpha}). "
                         f"Decisi√≥n basada en **{driver}**.")
            else:
                base = "Monte Carlo" if mc_reject is False else "Chi¬≤ cl√°sico"
                st.success(f"**Dictamen final (estricto):** No rechazar H‚ÇÄ (Œ±={alpha}). "
                           f"Decisi√≥n basada en **{base}**.")

        else:  # Docente
            # Priorizar Chi¬≤ cl√°sico; Monte Carlo como apoyo
            if chi2_reject:
                st.error(f"**Dictamen final (docente):** Rechazar H‚ÇÄ (Œ±={alpha}). Seg√∫n Chi¬≤ cl√°sico (p={pval:.4f}).")
            else:
                st.success(f"**Dictamen final (docente):** No rechazar H‚ÇÄ (Œ±={alpha}). Seg√∫n Chi¬≤ cl√°sico (p={pval:.4f}).")
                if mc_reject is not None and mc_reject != chi2_reject:
                    st.info("‚ÑπÔ∏è Nota: Monte Carlo lleg√≥ a una conclusi√≥n distinta (sensibilidad a esperados bajos).")

        # =========================
        # Gr√°fico
        # =========================
        fig = go.Figure()
        fig.add_bar(x=list(range(len(obs_counts))), y=obs_counts, name="Observados")
        fig.add_scatter(x=list(range(len(exp_counts))), y=exp_counts, mode="lines+markers",
                        name="Esperados", line=dict(color="red"))
        fig.update_layout(title=f"Chi¬≤ ‚Äî {dist_info}", xaxis_title="Valores", yaxis_title="Frecuencia")
        st.plotly_chart(fig, use_container_width=True)






# =========================
# TAB 3 ‚Äî DISTRIBUCIONES CONTINUAS
# =========================
with tabs[2]:
    st.header("üìà Ajuste de distribuciones continuas")
        # Banner con contexto actual
    st.info(f"üîé Nivel de significancia actual: **Œ± = {alpha}**\n\n"
            f"üìå Modo de decisi√≥n: **{decision_mode_cont}**")

    if data is not None:
        # --- üîß Mostrar solo columnas num√©ricas ---
        numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
        if not numeric_cols:
            st.error("‚ùå No hay columnas num√©ricas en el archivo. "
                    "Revise que el archivo tenga datos num√©ricos (sin texto).")
            st.stop()

        variable = st.selectbox("Seleccione variable continua", numeric_cols, key="var_cont")

        dist_choice = st.radio("Distribuci√≥n de referencia", ["Normal", "Exponencial", "Weibull", "Gamma", "Lognormal"], key="dist_cont")

        x = data[variable].dropna().values
        n = len(x)

        # Advertencia autom√°tica si el tama√±o muestral es peque√±o
        if n < 20:
            st.warning("‚ö†Ô∏è Tama√±o de muestra muy peque√±o (n < 20). "
                       "Las pruebas de bondad de ajuste pueden tener poca potencia estad√≠stica. "
                       "Interprete los resultados con precauci√≥n y considere aumentar la muestra.")

        # Inicializamos banderas
        have_lillie = False
        have_shap = False
        have_ad = False
        ad_pass = None  # para usar en dictamen final

        # =========================
        # NORMAL
        # =========================
        if dist_choice == "Normal":
            mu, sigma = np.mean(x), np.std(x, ddof=1)
            D, pval = kstest(x, "norm", args=(mu, sigma))
            dist_info = f"Normal(Œº={mu:.2f}, œÉ={sigma:.2f})"
    
            # ‚ûï Prueba Lilliefors (usando kstest_normal de statsmodels)
            from statsmodels.stats.diagnostic import kstest_normal
            stat_lillie, pval_lillie = kstest_normal(x)
            have_lillie = True

            # ‚ûï Shapiro‚ÄìWilk (solo si n < 20)
            if n < 20:
                from scipy.stats import shapiro
                stat_shap, pval_shap = shapiro(x)
                have_shap = True
                st.subheader("üßÆ Shapiro‚ÄìWilk (n < 20)")
                st.write(f"Estad√≠stico={stat_shap:.3f}, p-valor={pval_shap:.4f}")
                if pval_shap < alpha:
                    st.error(f"‚ùå Seg√∫n Shapiro‚ÄìWilk, se rechaza H‚ÇÄ al nivel Œ±={alpha}. "
                             "Los datos no parecen provenir de una distribuci√≥n Normal.")
                else:
                    st.success(f"‚úÖ Seg√∫n Shapiro‚ÄìWilk, no se rechaza H‚ÇÄ. "
                               "Los datos son consistentes con una distribuci√≥n Normal.")

            # ‚ûï Anderson‚ÄìDarling (n ‚â• 8)
            if n >= 8:
                from scipy.stats import anderson
                ad_res = anderson(x, dist="norm")
                have_ad = True
                st.subheader("üìä Anderson‚ÄìDarling (colas de la distribuci√≥n)")
                st.write(f"Estad√≠stico AD={ad_res.statistic:.3f}")
                niveles = ad_res.significance_level / 100
                idx = (np.abs(niveles - alpha)).argmin()
                valor_critico = ad_res.critical_values[idx]
                st.write(f"Valor cr√≠tico (Œ±={alpha}): {valor_critico:.3f}")
                if ad_res.statistic > valor_critico:
                    ad_pass = False
                    st.error(f"‚ùå Seg√∫n Anderson‚ÄìDarling, se rechaza H‚ÇÄ al nivel Œ±={alpha}. "
                             "Los datos no siguen Normal, con √©nfasis en colas.")
                else:
                    ad_pass = True
                    st.success(f"‚úÖ Seg√∫n Anderson‚ÄìDarling, no se rechaza H‚ÇÄ al nivel Œ±={alpha}. "
                               "Los datos son consistentes con una distribuci√≥n Normal.")

        # =========================
        # EXPONENCIAL
        # =========================
        elif dist_choice == "Exponencial":
            lam = 1 / np.mean(x)
            D, pval = kstest(x, "expon", args=(0, 1/lam))
            dist_info = f"Exponencial(Œª={lam:.2f})"

            # ‚ûï Prueba Lilliefors casera (Monte Carlo con par√°metros estimados)
            def lilliefors_expon(x, n_sim=500):
                lam = 1 / np.mean(x)
                D, _ = kstest(x, 'expon', args=(0, 1/lam))
                n = len(x)
                sims = []
                for _ in range(n_sim):
                    sample = np.random.exponential(scale=1/lam, size=n)
                    D_sim, _ = kstest(sample, 'expon', args=(0, 1/lam))
                    sims.append(D_sim)
                pval = np.mean(np.array(sims) >= D)
                return D, pval

            stat_lillie, pval_lillie = lilliefors_expon(x)
            have_lillie = True

            # ‚ûï Anderson‚ÄìDarling (n ‚â• 8)
            if n >= 8:
                from scipy.stats import anderson
                ad_res = anderson(x, dist="expon")
                have_ad = True
                st.subheader("üìä Anderson‚ÄìDarling (colas de la distribuci√≥n)")
                st.write(f"Estad√≠stico AD={ad_res.statistic:.3f}")
                niveles = ad_res.significance_level / 100
                idx = (np.abs(niveles - alpha)).argmin()
                valor_critico = ad_res.critical_values[idx]
                st.write(f"Valor cr√≠tico (Œ±={alpha}): {valor_critico:.3f}")
                if ad_res.statistic > valor_critico:
                    ad_pass = False
                    st.error(f"‚ùå Seg√∫n Anderson‚ÄìDarling, se rechaza H‚ÇÄ al nivel Œ±={alpha}. "
                             "Los datos no siguen Exponencial, con √©nfasis en colas.")
                else:
                    ad_pass = True
                    st.success(f"‚úÖ Seg√∫n Anderson‚ÄìDarling, no se rechaza H‚ÇÄ al nivel Œ±={alpha}. "
                               "Los datos son consistentes con una distribuci√≥n Exponencial.")

        # =========================
        # OTRAS DISTRIBUCIONES
        # =========================
        elif dist_choice == "Weibull":
            c, loc, scale = weibull_min.fit(x, floc=0)
            D, pval = kstest(x, "weibull_min", args=(c, loc, scale))
            dist_info = f"Weibull(Œ≤={c:.2f}, escala={scale:.2f})"

        elif dist_choice == "Gamma":
            a, loc, scale = gamma.fit(x, floc=0)
            D, pval = kstest(x, "gamma", args=(a, loc, scale))
            dist_info = f"Gamma(k={a:.2f}, Œ∏={scale:.2f})"

        else:  # Lognormal
            s, loc, scale = lognorm.fit(x, floc=0)
            D, pval = kstest(x, "lognorm", args=(s, loc, scale))
            dist_info = f"Lognormal(s={s:.2f}, escala={scale:.2f})"

        # =========================
        # Resultados KS
        # =========================
        st.subheader("üìà Kolmogorov‚ÄìSmirnov (KS cl√°sico)")
        st.write(f"Estad√≠stico KS={D:.3f}")
        st.write(f"p-valor={pval:.4f}")

        if pval < alpha:
            st.error(f"‚ùå Seg√∫n KS cl√°sico, se rechaza H‚ÇÄ. Los datos **no siguen** {dist_info}.")
        else:
            st.success(f"‚úÖ Seg√∫n KS cl√°sico, no se rechaza H‚ÇÄ. Los datos **siguen** {dist_info}.")

        # =========================
        # Resultados Lilliefors (solo Normal y Exponencial)
        # =========================
        if dist_choice in ["Normal", "Exponencial"] and have_lillie:
            st.subheader("üîπ Lilliefors (par√°metros estimados)")
            st.write(f"Estad√≠stico={stat_lillie:.3f}, p-valor={pval_lillie:.4f}")
            if pval_lillie < alpha:
                st.error(f"‚ùå Seg√∫n Lilliefors, se rechaza H‚ÇÄ al nivel Œ±={alpha}.")
            else:
                st.success(f"‚úÖ Seg√∫n Lilliefors, no se rechaza H‚ÇÄ. El ajuste a {dist_choice} es consistente.")

        # =========================
        # üìå DICTAMEN FINAL (criterio seleccionable)
        # =========================
        ks_reject = (pval < alpha)

        lillie_reject = None
        if dist_choice in ["Normal", "Exponencial"] and have_lillie:
            lillie_reject = (pval_lillie < alpha)

        shap_reject = None
        if dist_choice == "Normal" and have_shap:
            shap_reject = (pval_shap < alpha)

        ad_reject = None
        if have_ad:
            ad_reject = (ad_pass is False)  # AD no da p-valor; usamos cr√≠tico

        primary_results = []

        if dist_choice == "Normal":
            if n < 20 and have_shap:
                primary_results.append(("Shapiro‚ÄìWilk", shap_reject, f"p={pval_shap:.4f}"))
            else:
                if have_ad:
                    primary_results.append(("Anderson‚ÄìDarling", ad_reject, "comparaci√≥n con valor cr√≠tico"))
                if have_lillie:
                    primary_results.append(("Lilliefors", lillie_reject, f"p={pval_lillie:.4f}"))
                primary_results.append(("KS cl√°sico", ks_reject, f"p={pval:.4f}"))

        elif dist_choice == "Exponencial":
            if have_ad:
                primary_results.append(("Anderson‚ÄìDarling", ad_reject, "comparaci√≥n con valor cr√≠tico"))
            if have_lillie:
                primary_results.append(("Lilliefors", lillie_reject, f"p={pval_lillie:.4f}"))
            primary_results.append(("KS cl√°sico", ks_reject, f"p={pval:.4f}"))

        else:
            primary_results.append(("KS cl√°sico", ks_reject, f"p={pval:.4f}"))

        st.markdown("---")
        st.subheader("üßæ Dictamen final")

        if decision_mode_cont.startswith("Estricto"):
            reject_any = any(r for _, r, _ in primary_results if r is True)
            driver = next((name for name, r, _ in primary_results if r is True), primary_results[0][0])

            if reject_any:
                st.error(f"**Dictamen final (estricto):** Rechazar H‚ÇÄ (Œ±={alpha}). "
                         f"Decisi√≥n basada en **{driver}**.")
            else:
                base_name, _, base_detail = primary_results[0]
                st.success(f"**Dictamen final (estricto):** No rechazar H‚ÇÄ (Œ±={alpha}). "
                           f"Decisi√≥n basada en **{base_name}** ({base_detail}).")

        else:
            if any(name == "Lilliefors" for name, _, _ in primary_results):
                name, rej, detail = next((n, r, d) for n, r, d in primary_results if n == "Lilliefors")
            else:
                name, rej, detail = primary_results[0]

            if rej is True:
                st.error(f"**Dictamen final (docente):** Rechazar H‚ÇÄ (Œ±={alpha}). "
                         f"Decisi√≥n basada en **{name}** ({detail}).")
            else:
                st.success(f"**Dictamen final (docente):** No rechazar H‚ÇÄ (Œ±={alpha}). "
                           f"Decisi√≥n basada en **{name}** ({detail}).")

        # 4) Nota de discrepancias
        flags = []
        if have_ad and ad_reject is not None and ad_reject != ks_reject:
            flags.append("AD y KS llegan a conclusiones diferentes (colas vs centro).")
        if lillie_reject is not None and lillie_reject != ks_reject:
            flags.append("Lilliefors y KS difieren (par√°metros estimados).")
        if shap_reject is not None and dist_choice == "Normal" and n < 20 and shap_reject != ks_reject:
            flags.append("Shapiro‚ÄìWilk y KS difieren (n peque√±o).")

        if flags:
            st.warning("**Discrepancias detectadas:** " + " ".join(flags))

        # Tabla resumen de p-valores
        summary_rows = [{"Prueba": "KS cl√°sico", "p-valor": pval}]
        if have_lillie:
            summary_rows.append({"Prueba": "Lilliefors", "p-valor": pval_lillie})
        if have_shap:
            summary_rows.append({"Prueba": "Shapiro‚ÄìWilk", "p-valor": pval_shap})
        if have_ad:
            summary_rows.append({"Prueba": "Anderson‚ÄìDarling", "p-valor": "Basado en cr√≠tico"})

        st.markdown("**Resumen de p-valores (referencia):**")
        st.table(pd.DataFrame(summary_rows))

        # =========================
        # Gr√°fico
        # =========================
        hist = np.histogram(x, bins=20, density=True)
        fig = go.Figure()
        fig.add_bar(x=hist[1][:-1], y=hist[0], name="Datos", opacity=0.6)
        xs = np.linspace(min(x), max(x), 200)
        if dist_choice == "Normal":
            ys = norm.pdf(xs, mu, sigma)
        elif dist_choice == "Exponencial":
            ys = expon.pdf(xs, 0, 1/lam)
        elif dist_choice == "Weibull":
            ys = weibull_min.pdf(xs, c, loc, scale)
        elif dist_choice == "Gamma":
            ys = gamma.pdf(xs, a, loc, scale)
        else:
            ys = lognorm.pdf(xs, s, loc, scale)
        fig.add_scatter(x=xs, y=ys, mode="lines", name=f"{dist_choice} te√≥rica", line=dict(color="red"))
        fig.update_layout(title=f"Ajuste {dist_choice}", xaxis_title="Valores", yaxis_title="Densidad")
        st.plotly_chart(fig, use_container_width=True)


# =========================
# TAB NUEVO ‚Äî VALIDACI√ìN DISCRETA AVANZADA
# =========================
with tabs[3]:
    st.header("üßÆ Validaci√≥n avanzada de modelos discretos")

    # Banner de contexto (Œ± y modo de decisi√≥n para discretas)
    st.info(f"üîé Nivel de significancia actual: **Œ± = {alpha}**\n\n"
            f"üìå Modo de decisi√≥n: **{decision_mode_disc}**")

    st.markdown("Esta secci√≥n valida **modelos discretos** (Poisson, Binomial, Hipergeom√©trica) "
                "usando log-verosimilitud, AIC/BIC y an√°lisis de residuos (Pearson y deviance). "
                "Se complementa con Chi¬≤ y opci√≥n Monte Carlo cuando aplique.")

    if data is not None:
        # Selecci√≥n de variable y distribuci√≥n
        # --- üîß Mostrar solo columnas num√©ricas ---
        numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
        if not numeric_cols:
            st.error("‚ùå No hay columnas num√©ricas en el archivo. "
                    "Verifique que las columnas contengan datos num√©ricos (conteos o frecuencias).")
            st.stop()

        variable = st.selectbox("Seleccione variable discreta", numeric_cols, key="val_disc_var")

        dist_choice = st.radio("Modelo discreto a validar",
                               ["Poisson", "Binomial", "Hipergeom√©trica"],
                               key="val_disc_dist")

        # Vector de observaciones discretas
        x = data[variable].dropna().values
        # --- üîß Validaci√≥n de discreci√≥n ---
        if np.any(x % 1 != 0):
            st.warning("‚ö†Ô∏è La variable seleccionada tiene valores decimales. "
                    "Se redondear√°n al entero m√°s cercano para aplicar el modelo discreto.")
            x = np.round(x).astype(int)
        else:
            x = x.astype(int)

        x = np.clip(x, 0, None)

        n = len(x)

        # Conteos observados por categor√≠a (0,1,2,...,k)
        obs_counts = np.bincount(x)
        k_vals = np.arange(len(obs_counts))

        # Advertencia por tama√±o muestral
        if n < 20:
            st.warning("‚ö†Ô∏è Tama√±o muestral peque√±o (n < 20). "
                       "Chi¬≤ puede ser inestable; use Monte Carlo o pruebas exactas cuando aplique.")

        # -------------------------------------------------
        # 1) Par√°metros, loglike y probabilidades te√≥ricas
        # -------------------------------------------------
        if dist_choice == "Poisson":
            lam = np.mean(x)
            pmf = poisson.pmf(k_vals, lam)
            loglike = np.sum(poisson.logpmf(x, lam))
            param_text = f"ŒªÃÇ = {lam:.4f}"
            k_params = 1

        elif dist_choice == "Binomial":
            # El usuario debe especificar n_trials (ensayos por observaci√≥n)
            n_trials = st.number_input("N√∫mero de ensayos por observaci√≥n (n)", 1, 1000, 10, key="val_disc_ntrials")
            # Estimaci√≥n pÃÇ = media(x)/n_trials (supuesto cl√°sico)
            p = np.clip(np.mean(x) / n_trials, 1e-9, 1-1e-9)
            pmf = binom.pmf(k_vals, n_trials, p)
            loglike = np.sum(binom.logpmf(x, n_trials, p))
            param_text = f"n = {int(n_trials)}, pÃÇ = {p:.4f}"
            k_params = 1  # (asumiendo n_trials fijo y p estimado)

        else:  # Hipergeom√©trica
            # Parametrizaci√≥n: N poblaci√≥n, K √©xitos en poblaci√≥n, n_s tama√±o de muestra por observaci√≥n
            N = st.number_input("Tama√±o poblaci√≥n (N)", 1, 100000, 200, key="val_disc_N")
            K = st.number_input("√âxitos en poblaci√≥n (K)", 0, int(N), min(int(N)//4, int(N)), key="val_disc_K")
            n_s = st.number_input("Tama√±o de muestra por observaci√≥n (n_s)", 1, int(N), min(10, int(N)), key="val_disc_ns")
            # pmf en soporte observado
            pmf = hypergeom.pmf(k_vals, N, K, n_s)
            # log-like: producto de pmf de cada observaci√≥n individual
            # (si x contiene conteos de √©xitos en submuestras de tama√±o n_s)
            with np.errstate(divide='ignore'):
                loglike = np.sum(hypergeom.logpmf(x, N, K, n_s))
            param_text = f"N={int(N)}, K={int(K)}, n_s={int(n_s)}"
            k_params = 2  # (K y n_s como dados por usuario ‚Üí si los tratas como estimados, ajustar)

        # Normaliza por seguridad (evitar peque√±os errores num√©ricos)
        pmf = np.clip(pmf, 1e-15, 1.0)
        pmf = pmf / pmf.sum()

        # -------------------------------------------------
        # 2) AIC/BIC
        # -------------------------------------------------
        aic = -2 * loglike + 2 * k_params
        bic = -2 * loglike + k_params * np.log(n)

        st.subheader("üìã Log-verosimilitud y criterios de informaci√≥n")
        st.table(pd.DataFrame({"Estad√≠stico": ["Loglike", "AIC", "BIC", "Par√°metros"],
                               "Valor": [loglike, aic, bic, param_text]}))

        # -------------------------------------------------
        # 3) Esperados, Chi¬≤ y Monte Carlo (si aplica)
        # -------------------------------------------------
        exp_counts = pmf * n
        # Ajuste de normalizaci√≥n por seguridad
        exp_counts *= n / exp_counts.sum()

        # Chequeo de esperados bajos
        low_expected = int(np.sum(exp_counts < 5))
        if low_expected > 0:
            st.warning(f"‚ö†Ô∏è Se detectaron {low_expected} categor√≠as con esperados < 5. "
                       "El Chi¬≤ puede perder validez. Considere **reagrupar** o usar **Monte Carlo**.")

        chi2, pval = chisquare(obs_counts, f_exp=exp_counts)

        st.subheader("üìà Chi¬≤ cl√°sico (referencia)")
        st.write(f"Estad√≠stico = {chi2:.3f}, p-valor = {pval:.4f}")

        # Monte Carlo para p-valor de Chi¬≤ cuando n es peque√±o o hay esperados bajos
        pval_mc = None
        if (n < 20) or (low_expected > 0):
            st.caption("üé≤ Monte Carlo activado por n peque√±o o esperados bajos.")
            def chi2_montecarlo(obs, exp, n_sim=5000):
                chi2_obs, _ = chisquare(obs, f_exp=exp)
                probs = exp / np.sum(exp)
                n_tot = int(np.sum(obs))
                sims = np.empty(n_sim)
                for i in range(n_sim):
                    sim_data = np.random.multinomial(n_tot, probs)
                    sims[i], _ = chisquare(sim_data, f_exp=exp)
                return np.mean(sims >= chi2_obs)

            pval_mc = chi2_montecarlo(obs_counts, exp_counts, n_sim=5000)
            st.write(f"**Chi¬≤ Monte Carlo:** p-valor simulado = {pval_mc:.4f}")

        # -------------------------------------------------
        # 4) Residuos (Pearson y Deviance) y gr√°ficos
        # -------------------------------------------------
        st.subheader("üìä Residuos (diagn√≥stico)")

        # Pearson residuals
        with np.errstate(divide='ignore', invalid='ignore'):
            pearson_res = (obs_counts - exp_counts) / np.sqrt(np.where(exp_counts > 0, exp_counts, np.nan))

        # Deviance residuals aproximados para conteos (evitar 0*log(0))
        dev_terms = np.where(obs_counts > 0,
                             2 * obs_counts * np.log(np.where(exp_counts > 0, obs_counts / exp_counts, np.nan)),
                             0.0)
        deviance = np.nansum(dev_terms)

        st.write(f"Deviance total (aprox.): {deviance:.3f}")

        # Gr√°fico: Observado vs Esperado
        fig_oe = go.Figure()
        fig_oe.add_bar(x=k_vals, y=obs_counts, name="Observados")
        fig_oe.add_scatter(x=k_vals, y=exp_counts, mode="lines+markers", name="Esperados", line=dict(color="red"))
        fig_oe.update_layout(title=f"Observado vs Esperado ‚Äî {dist_choice}",
                             xaxis_title="Clases", yaxis_title="Frecuencia")
        st.plotly_chart(fig_oe, use_container_width=True)

        # Gr√°fico: Residuos de Pearson
        fig_pr = go.Figure()
        fig_pr.add_bar(x=k_vals, y=np.nan_to_num(pearson_res), name="Residuos de Pearson")
        fig_pr.update_layout(title="Residuos de Pearson por clase",
                             xaxis_title="Clases", yaxis_title="(O-E)/‚àöE")
        st.plotly_chart(fig_pr, use_container_width=True)

        # -------------------------------------------------
        # 5) Dictamen final (alineado con Tab 2)
        # -------------------------------------------------
        st.markdown("---")
        st.subheader("üßæ Dictamen final")

        chi2_reject = (pval < alpha)
        mc_reject = (pval_mc is not None) and (pval_mc < alpha)

        if decision_mode_disc.startswith("Estricto"):
            # Estricto/Industrial: si alguna evidencia principal rechaza ‚Üí rechazar
            if chi2_reject or mc_reject:
                driver = "Monte Carlo" if mc_reject else "Chi¬≤ cl√°sico"
                st.error(f"**Dictamen final (estricto):** Rechazar H‚ÇÄ (Œ±={alpha}). "
                         f"Decisi√≥n basada en **{driver}**.")
            else:
                base = "Monte Carlo" if pval_mc is not None else "Chi¬≤ cl√°sico"
                st.success(f"**Dictamen final (estricto):** No rechazar H‚ÇÄ (Œ±={alpha}). "
                           f"Decisi√≥n basada en **{base}**.")

        else:
            # Docente: prioriza Chi¬≤; Monte Carlo es apoyo
            if chi2_reject:
                st.error(f"**Dictamen final (docente):** Rechazar H‚ÇÄ (Œ±={alpha}). "
                         f"Seg√∫n Chi¬≤ (p={pval:.4f}).")
            else:
                st.success(f"**Dictamen final (docente):** No rechazar H‚ÇÄ (Œ±={alpha}). "
                           f"Seg√∫n Chi¬≤ (p={pval:.4f}).")
                if pval_mc is not None and (mc_reject != chi2_reject):
                    st.info("‚ÑπÔ∏è Nota: Monte Carlo lleg√≥ a una conclusi√≥n distinta; sensible a esperados bajos.")

        # Nota de uso de AIC/BIC (comparativo)
        st.caption("üìå **AIC/BIC** son comparativos entre **modelos**: valores m√°s bajos indican mejor ajuste relativo. "
                   "Use esta secci√≥n para comparar Poisson vs Binomial vs Hipergeom√©trica ante la misma variable.")




# =========================
# TAB 5 ‚Äî VALIDACI√ìN AVANZADA
# =========================
with tabs[4]:
    st.header("üìä Validaci√≥n avanzada de modelos continuos")

    # 1. Banner con contexto (Œ± y modo de decisi√≥n)
    st.info(f"üîé Nivel de significancia actual: **Œ± = {alpha}**\n\n"
            f"üìå Modo de decisi√≥n: **{decision_mode_cont}**")

    st.markdown("‚ÑπÔ∏è Esta validaci√≥n avanzada aplica √∫nicamente a **distribuciones continuas** "
                "(Normal, Exponencial, Weibull). Se analizan log-verosimilitud, criterios de informaci√≥n "
                "y gr√°ficos Q‚ÄìQ, P‚ÄìP.")

    if data is not None:
        variable = st.selectbox("Seleccione variable", data.columns, key="val_av")
        dist_choice = st.radio("Distribuci√≥n", ["Normal", "Exponencial", "Weibull"], key="val_dist")
        x = data[variable].dropna().values
        n = len(x)

        # 4. Advertencia para muestras peque√±as
        if n < 20:
            st.warning("‚ö†Ô∏è Tama√±o muestral peque√±o (n < 20). "
                       "Los criterios AIC/BIC y las gr√°ficas Q‚ÄìQ, P‚ÄìP pueden ser poco confiables. "
                       "Considere aumentar el tama√±o de muestra.")

        # Ajuste de par√°metros y log-verosimilitud
        if dist_choice == "Normal":
            mu, sigma = np.mean(x), np.std(x, ddof=1)
            loglike = np.sum(norm.logpdf(x, mu, sigma))
            params = (mu, sigma)
            theo_q = norm.ppf(np.linspace(0.01, 0.99, n), *params)

        elif dist_choice == "Exponencial":
            lam = 1/np.mean(x)
            loglike = np.sum(expon.logpdf(x, 0, 1/lam))
            params = (0, 1/lam)
            theo_q = expon.ppf(np.linspace(0.01, 0.99, n), *params)

        else:  # Weibull
            c, loc, scale = weibull_min.fit(x, floc=0)
            loglike = np.sum(weibull_min.logpdf(x, c, loc, scale))
            params = (c, loc, scale)
            theo_q = weibull_min.ppf(np.linspace(0.01, 0.99, n), *params)

        # Criterios de informaci√≥n
        aic = -2*loglike + 2*len(params)
        bic = -2*loglike + len(params)*np.log(n)

        # 2. Resultados con subt√≠tulo m√°s claro
        st.subheader("üìã Resultados de log-verosimilitud y criterios de informaci√≥n")
        st.table(pd.DataFrame({"Estad√≠stico": ["Loglike", "AIC", "BIC"],
                               "Valor": [loglike, aic, bic]}))

        # Q-Q Plot
        st.subheader("üìâ Gr√°fico Q‚ÄìQ")
        obs_q = np.sort(x)
        fig = go.Figure()
        fig.add_scatter(x=theo_q, y=obs_q, mode="markers", name="Datos")
        fig.add_scatter(x=theo_q, y=theo_q, mode="lines", name="45¬∞", line=dict(dash="dash"))
        fig.update_layout(title=f"Gr√°fico Q‚ÄìQ ({dist_choice})", xaxis_title="Cuantiles te√≥ricos", yaxis_title="Cuantiles observados")
        st.plotly_chart(fig, use_container_width=True)

        # P-P Plot
        st.subheader("üìà Gr√°fico P‚ÄìP")
        ecdf = np.arange(1, n+1)/n
        if dist_choice == "Normal":
            cdf_theo = norm.cdf(np.sort(x), mu, sigma)
        elif dist_choice == "Exponencial":
            cdf_theo = expon.cdf(np.sort(x), 0, 1/lam)
        else:
            cdf_theo = weibull_min.cdf(np.sort(x), c, loc, scale)

        fig2 = go.Figure()
        fig2.add_scatter(x=cdf_theo, y=ecdf, mode="markers", name="Datos")
        fig2.add_scatter(x=[0,1], y=[0,1], mode="lines", name="45¬∞", line=dict(dash="dash"))
        fig2.update_layout(title=f"Gr√°fico P‚ÄìP ({dist_choice})", xaxis_title="CDF te√≥rica", yaxis_title="CDF emp√≠rica")
        st.plotly_chart(fig2, use_container_width=True)

        # 3. Dictamen final en base a AIC/BIC
        st.markdown("---")
        st.subheader("üßæ Dictamen final")

        if aic < bic:
            st.success(f"‚úÖ El modelo {dist_choice} parece razonable: AIC={aic:.2f}, BIC={bic:.2f}. "
                       "Un AIC m√°s bajo sugiere mejor ajuste relativo.")
        else:
            st.warning(f"‚ö†Ô∏è El modelo {dist_choice} no es √≥ptimo: AIC={aic:.2f} ‚â• BIC={bic:.2f}. "
                       "Considere probar otras distribuciones o validar con datos adicionales.")

        # 5. Interpretaciones aplicadas
        if dist_choice == "Normal":
            st.info("üìå Una buena alineaci√≥n en los gr√°ficos Q‚ÄìQ y P‚ÄìP confirma que las fluctuaciones "
                    "siguen un patr√≥n gaussiano. Esto es esperado en par√°metros como prote√≠na o densidad de la leche.")
        elif dist_choice == "Exponencial":
            st.info("üìå Un buen ajuste exponencial indica que los tiempos hasta eventos (fallas, vida √∫til) "
                    "se comportan como procesos de memoria nula, t√≠pico en microbiolog√≠a o fallas aleatorias.")
        else:
            st.info("üìå En Weibull, el par√°metro Œ≤ permite interpretar el tipo de falla: "
                    "Œ≤<1 (tempranas), Œ≤‚âà1 (azarosas), Œ≤>1 (desgaste).")

# =========================
# TAB 5 ‚Äî ESCENARIOS CR√çTICOS
# =========================
with tabs[5]:
    st.header("‚ö†Ô∏è Escenarios cr√≠ticos en industria l√°ctea")
    st.caption("üè≠ Enfoque industrial: cada decisi√≥n estad√≠stica se interpreta como riesgo o medida de control en procesos l√°cteos.")
    st.info("üîç En esta secci√≥n se simulan **problemas reales de la industria l√°ctea**. "
            "Se aplican distribuciones para modelar riesgos y se interpretan los resultados con base en estad√≠sticos, "
            "p-valores y curvas de supervivencia.")

    if data is not None:
        escenario = st.selectbox("Seleccione escenario", 
                                 ["Contaminaci√≥n microbiol√≥gica", "Falla en cadena de fr√≠o", "Comparaci√≥n vida √∫til"])
        variable = st.selectbox("Variable a analizar", data.columns, key="var_scen")
        x = data[variable].dropna().values
        n = len(x)

        # =========================
        # ESCENARIO 1: CONTAMINACI√ìN MICROBIOL√ìGICA
        # =========================
        if escenario == "Contaminaci√≥n microbiol√≥gica":
            lam = np.mean(x)

            # --- üîß Correcci√≥n: validar si los datos son enteros ---
            if np.any(x % 1 != 0):
                st.warning("‚ö†Ô∏è La variable seleccionada tiene valores decimales. "
                        "Se redondear√°n al entero m√°s cercano para aplicar el modelo de Poisson.")
                x = np.round(x).astype(int)
            else:
                x = x.astype(int)

            # Evitar valores negativos (Poisson no los permite)
            x = np.clip(x, 0, None)

            # --- C√°lculo corregido de esperados ---
            exp_counts = [poisson.pmf(k, lam) * len(x) for k in range(int(max(x)) + 1)]
            exp_counts = np.array(exp_counts)
            exp_counts *= len(x) / exp_counts.sum()
            obs_counts = np.bincount(x, minlength=len(exp_counts))


            chi2, pval = chisquare(obs_counts, f_exp=exp_counts)

            st.subheader("üìà Chi¬≤ cl√°sico (Poisson)")
            st.write(f"Estad√≠stico = {chi2:.3f}, p-valor = {pval:.4f}")

            # Monte Carlo si n es peque√±o o hay esperados bajos
            low_expected = np.sum(exp_counts < 5)
            pval_mc = None
            if n < 20 or low_expected > 0:
                st.caption("üé≤ Monte Carlo activado autom√°ticamente (n peque√±o o esperados bajos).")

                def chi2_montecarlo(obs, exp, n_sim=5000):
                    chi2_obs, _ = chisquare(obs, f_exp=exp)
                    probs = exp / np.sum(exp)
                    n_tot = np.sum(obs)
                    sims = []
                    for _ in range(n_sim):
                        sim_data = np.random.multinomial(n_tot, probs)
                        chi2_sim, _ = chisquare(sim_data, f_exp=exp)
                        sims.append(chi2_sim)
                    pval_mc = np.mean([s >= chi2_obs for s in sims])
                    return chi2_obs, pval_mc

                chi2_mc, pval_mc = chi2_montecarlo(obs_counts, exp_counts)
                st.subheader("üé≤ Chi¬≤ con Monte Carlo")
                st.write(f"Estad√≠stico = {chi2_mc:.3f}, p-valor simulado = {pval_mc:.4f}")

            # Dictamen final
            st.subheader("üßæ Dictamen final")
            if (pval < alpha) or (pval_mc is not None and pval_mc < alpha):
                st.error(f"‚ùå Rechazar H‚ÇÄ (Œ±={alpha}). Posible riesgo microbiol√≥gico detectado.")
            else:
                st.success(f"‚úÖ No rechazar H‚ÇÄ (Œ±={alpha}). Conteos consistentes con Poisson (evento raro).")

            st.caption("üìå Interpretaci√≥n: Si el modelo Poisson es v√°lido, los conteos de UFC corresponden "
                       "a eventos raros independientes. Un rechazo de H‚ÇÄ sugiere contaminaci√≥n sistem√°tica o fallas higi√©nicas.")

            # Gr√°fico Observados vs Esperados
            fig = go.Figure()
            fig.add_bar(x=list(range(len(obs_counts))), y=obs_counts, name="Observados")
            fig.add_scatter(x=list(range(len(exp_counts))), y=exp_counts, mode="lines+markers",
                            name="Esperados", line=dict(color="red"))
            fig.update_layout(title="Chi¬≤ ‚Äî Ajuste Poisson", xaxis_title="Conteos", yaxis_title="Frecuencia")
            st.plotly_chart(fig, use_container_width=True)

        # =========================
        # ESCENARIO 2: FALLA EN CADENA DE FR√çO
        # =========================
        elif escenario == "Falla en cadena de fr√≠o":
            c, loc, scale = weibull_min.fit(x, floc=0)
            loglike = np.sum(weibull_min.logpdf(x, c, loc, scale))

            st.subheader("üìä Ajuste Weibull")
            st.write(f"Weibull(Œ≤={c:.2f}, escala={scale:.2f}) ‚Äî Loglike={loglike:.2f}")
            st.info("üîπ Interpretaci√≥n: Œ≤<1 fallas tempranas, Œ≤‚âà1 azarosas, Œ≤>1 desgaste.")
            st.caption("üìå Contexto t√©cnico: Identificar si la p√©rdida de fr√≠o genera fallas prematuras (Œ≤<1) "
                       "o deterioros por envejecimiento acelerado (Œ≤>1).")

            # Gr√°fico supervivencia Weibull
            xs = np.linspace(min(x), max(x), 200)
            fig = go.Figure()
            fig.add_scatter(x=xs, y=weibull_min.sf(xs, c, loc, scale), 
                            mode="lines", name="Weibull ‚Äî supervivencia", line=dict(color="blue"))
            fig.update_layout(title="Curva de supervivencia Weibull",
                              xaxis_title="Tiempo", yaxis_title="S(t)")
            st.plotly_chart(fig, use_container_width=True)

            # Dictamen final
            st.subheader("üßæ Dictamen final")
            if c < 1:
                st.warning("‚ö†Ô∏è Riesgo de fallas tempranas: Œ≤<1 ‚Üí productos sensibles a ruptura de fr√≠o.")
            elif c > 1:
                st.error("‚ùå Riesgo por desgaste acelerado: Œ≤>1 ‚Üí deterioro progresivo en cadena de fr√≠o.")
            else:
                st.success("‚úÖ Fallas aleatorias: Œ≤‚âà1 ‚Üí comportamiento azaroso.")

        # =========================
        # ESCENARIO 3: COMPARACI√ìN VIDA √öTIL
        # =========================
        else:
            lam = 1/np.mean(x)
            c, loc, scale = weibull_min.fit(x, floc=0)

            xs = np.linspace(min(x), max(x), 200)
            fig = go.Figure()
            fig.add_scatter(x=xs, y=expon.sf(xs, 0, 1/lam), name="Exponencial ‚Äî refrigeraci√≥n")
            fig.add_scatter(x=xs, y=weibull_min.sf(xs, c, loc, scale), name="Weibull ‚Äî ruptura fr√≠o")
            fig.update_layout(title="Curvas de supervivencia ‚Äî Vida √∫til",
                              xaxis_title="Tiempo", yaxis_title="Supervivencia (S(t))")
            st.plotly_chart(fig, use_container_width=True)

            # Dictamen final
            st.subheader("üßæ Dictamen final")
            st.info("üîπ La curva m√°s baja indica mayor riesgo de p√©rdida de calidad. "
                    "Comparar ambas curvas ayuda a decidir pol√≠ticas de control: "
                    "reforzar refrigeraci√≥n, ajustar tiempos de distribuci√≥n o "
                    "establecer l√≠mites de seguridad en log√≠stica.")
                    


